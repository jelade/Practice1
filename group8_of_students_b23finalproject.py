# -*- coding: utf-8 -*-
"""Group8_of Students_B23FinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MlnJn0bF-08hvQW_-x9et84DAEZ2Z5_8
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import datasets

# Get Data: Do not touch it.
def get_data():
  data_url = "http://lib.stat.cmu.edu/datasets/boston"
  raw_df = pd.read_csv(data_url, sep="\s+", skiprows=22, header=None)
  X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])
  y = raw_df.values[1::2, 2]
  return X,y

X,y  = get_data()

X.shape

# cgs
def cgs(A):
  """
    Q,R = cgs(A)
    Apply classical Gram-Schmidt to mxn rectangular/square matrix. 

    Parameters
    -------
    A: mxn rectangular/square matrix   

    Returns
    -------
    Q: mxn square matrix
    R: nxn upper triangular matrix

  """
  m = len(A)
  n = len(A[0])
  R = np.zeros((n,n))
  Q = np.ones((m,n))
  for k in range(n):
    w = A[:,k]
    for j in range(1,k-1):
      R[j,k] = np.dot(Q[:,j],w)
    for j in range(k):
        w = w - R[j,k]*Q[:,j]
    R[k,k] = np.linalg.norm(w)
    Q[:,k] = w/R[k,k]

  return R,Q

# Implement BACK SUBS
def backsubs(U, b):

  """
  x = backsubs(U, b)
  Apply back substitution for the square upper triangular system Ux=b. 

  Parameters
  -------
    U: nxn square upper triangular array
    b: n array
    

  Returns
  -------
    x: n array
  """

  n= U.shape[1]
  x= np.zeros((n,))
  b_copy= np.copy(b)

  if U[n-1,n-1]==0.0:
    if b[n-1] != 0.0:
      print("System has no solution.")
  
  else:
    x[n-1]= b_copy[n-1]/U[n-1,n-1]
  for i in range(n-2,-1,-1):
    if U[i,i]==0.0:
      if b[i]!= 0.0:
        print("System has no solution.")
    else:
      for j in range(i,n):
        b_copy[i] -=U[i,j]*x[j]
      x[i]= b_copy[i]/U[i,i]
  return x

def cgss(A,Y):
  R,Q = cgs(A)
  y = Q.T@Y
  y_ = backsubs(R,y)
  return y_
cgss(X,y)

# Add ones
def add_ones(w):

  one = np.ones((len(w))).reshape(len(w),1)

  w = np.hstack((one,w))
  return w

## Add ones to X
X= add_ones(X)
X

def split_data(X,Y, train_size):
  # ADD YOUR CODES
  # shuffle the data before splitting it
  x_train_size = round(len(X)* train_size)
  x_test_size = len(X) - x_train_size
  
  np.random.shuffle(X)
  np.random.shuffle(Y)
  X_train = X[:x_train_size]
  X_test = X[x_train_size:]
  y_train = y[:x_train_size]
  y_test = y[x_train_size:]


  return X_train, X_test, y_train, y_test

# Split (X,y) into X_train, X_test, y_train, y_test
X_train, X_test, y_train, y_test= split_data(X,y,0.8)

def mse(y, y_pred):
  error = y- y_pred
  ms = np.dot(error,error)/len(y)
  return ms

def normalEquation(X,y):
    # ADD YOUR CODES

    theta_hat = np.linalg.inv(np.transpose(X) @ X) @ (np.transpose(X)@y)
    return theta_hat

b = normalEquation(X_train,y_train)
print(b)

def predict(x,a):
  y = x@a
  return y

Y = predict(X_test,b)

u = mse(y_test,Y)
u

class LinearRegression:

  def __init__(self, model= "lin"):
      # ADD YOUR CODES
     self.model = model
  def fit(self,x,y):
      # ADD YOUR CODES
      self.x = x
      self.y = y
      if self.model == "lin":
        self.theta = normalEquation(self.x,self.y)
      elif self.model == "cgs":
        self.theta = cgss(self.x,self.y)
      else:
        return "Unknown estimator"
        
        #norma
    
  def predict(self,x):
      #ADD YOUR CODES
      y_predict = x @ self.theta

      return y_predict

# Instanciate the LinearRegression class 
model= LinearRegression("cgs")

model1 = LinearRegression()

# Train the model

model.fit(X_train, y_train)
model1.fit(X_train, y_train)

# print the learned theta

print(model.theta)
print(model1.theta)

# Make a prediction on X_test

y_pp = model.predict(X_test)
y_pp1 = model1.predict(X_test)

print(y_pp)


print(y_pp1)

# Compute the MSE (Evaluate both, regression and classification)

normal = mse(y_test,y_pp)
print(normal)

normal1 = mse(y_test,y_pp1)

print(normal1)

